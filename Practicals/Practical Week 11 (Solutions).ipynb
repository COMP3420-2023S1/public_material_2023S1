{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Week 11: Sequence-to-sequence models\n",
    "\n",
    "There are three important tasks to complete this week:\n",
    "\n",
    "1. Learning how to use LSTM and Transformers to process data sequences. You will find yourself waiting a long time\n",
    "   for many of these computations to complete. While you wait:\n",
    "\n",
    "2. Complete the course survey. It's in ilearn, and this link will show you how to view it and complete it:\n",
    "https://ishare.mq.edu.au/prod/items/912f85f6-70e8-48a5-94ca-d3928e9d7c3c/1/viewcontent/\n",
    "\n",
    "\n",
    "3. Sign up to get API access to OpenAI, which you will need for next week's practical. https://platform.openai.com/signup \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to sequence\n",
    "\n",
    "We're going to do a task that even ChatGPT-4 doesn't get right: arithmetic on long integer sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell creates a list of example bitwise-or calculations using python's `|` operator.\n",
    "\n",
    "If you aren't familiar with Python's bit-handling functions, or what a bitwise-or does, here's a short\n",
    "introduction: https://realpython.com/python-bitwise-operators/#bitwise-logical-operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_facts = []\n",
    "for i in range(64):\n",
    "    for j in range(64):\n",
    "        k = i | j\n",
    "        math_facts.append(f\"{i:06b} | {j:06b} = {k:06b}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the random library (or any other way you like) to see a few samples from the `math_facts` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001100 | 000010 = 001110.',\n",
       " '011110 | 001110 = 011110.',\n",
       " '100000 | 010000 = 110000.',\n",
       " '101000 | 000100 = 101100.',\n",
       " '100110 | 101110 = 101110.']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(math_facts,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We need to process these strings so that they can be used in a sequence-to-sequence model.\n",
    "\n",
    "- For each string, split it up on the equals sign.\n",
    "- On the left hand side of the equals sign, add a space between each digit so that each digit is its own token\n",
    "- On the right hand side of the equals sign, generate 9 training samples. Encode 0 as `tf.convert_to_tensor([1,0,0])`, 1 as `tf.convert_to_tensor([0,1,0])` and \".\" as `tf.convert_to_tensor([0,0,1])`\n",
    "\n",
    "e.g. suppose you were working with the statement:\n",
    "\n",
    "```001000 | 010101 = 011101.```\n",
    "\n",
    "Then you want to turn this into:\n",
    "\n",
    "```\n",
    "{'context': '0 0 1 0 0 0 | 0 1 0 1 0 1 =', 'next_token': '0'}, \n",
    "{'context': '0 0 1 0 0 0 | 0 1 0 1 0 1 = 0', 'next_token': '1'}, \n",
    "{'context': '0 0 1 0 0 0 | 0 1 0 1 0 1 = 0 1', 'next_token': '1'},\n",
    "{'context': '0 0 1 0 0 0 | 0 1 0 1 0 1 = 0 1 1', 'next_token': '1'},\n",
    "{'context': '0 0 1 0 0 0 | 0 1 0 1 0 1 = 0 1 1 1', 'next_token': '0'},\n",
    "{'context': '0 0 1 0 0 0 | 0 1 0 1 0 1 = 0 1 1 1 0', 'next_token': '1'},\n",
    "{'context': '0 0 1 0 0 0 | 0 1 0 1 0 1 = 0 1 1 1 0 1', 'next_token': '.'},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "r = re.compile('(\\d)(\\d)(\\d)(\\d)(\\d)(\\d)'\n",
    "               ' \\| '\n",
    "               '(\\d)(\\d)(\\d)(\\d)(\\d)(\\d)'\n",
    "               ' = '\n",
    "               '(\\d)(\\d)(\\d)(\\d)(\\d)(\\d)\\.'\n",
    "              )\n",
    "data = []\n",
    "token_lookup = {'0': [1,0,0], '1': [0,1,0]}\n",
    "\n",
    "for fact in math_facts:\n",
    "    g = r.search(fact)\n",
    "    lhs = f\"{g[1]} {g[2]} {g[3]} {g[4]} {g[5]} {g[6]} | \"\n",
    "    lhs += f\"{g[7]} {g[8]} {g[9]} {g[10]} {g[11]} {g[12]} =\"\n",
    "    \n",
    "    data.append({'context': lhs, 'next_token': token_lookup[g[13]]} )\n",
    "    lhs += f\" {g[13]}\"\n",
    "    data.append({'context': lhs, 'next_token': token_lookup[g[14]]} )\n",
    "    lhs += f\" {g[14]}\"\n",
    "    data.append({'context': lhs, 'next_token': token_lookup[g[15]]} )\n",
    "    lhs += f\" {g[15]}\"\n",
    "    data.append({'context': lhs, 'next_token': token_lookup[g[16]]} )\n",
    "    lhs += f\" {g[16]}\"\n",
    "    data.append({'context': lhs, 'next_token': token_lookup[g[17]]} )\n",
    "    lhs += f\" {g[17]}\"\n",
    "    data.append({'context': lhs, 'next_token': token_lookup[g[18]]} )\n",
    "    lhs += f\" {g[18]}\"\n",
    "    #data.append({'context': lhs, 'next_token': tf.convert_to_tensor([0,0,1])} )\n",
    "    data.append({'context': lhs, 'next_token': [0,0,1]} )\n",
    "\n",
    "df = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a sample of the `df` dataframe to confirm it matches what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>next_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>0 0 1 1 1 1 ^ 0 1 0 0 0 0 = 0 1 1</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27678</th>\n",
       "      <td>1 1 1 1 0 1 ^ 1 1 0 0 1 0 =</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18078</th>\n",
       "      <td>1 0 1 0 0 0 ^ 0 1 0 1 1 0 = 1 1 1 1</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14047</th>\n",
       "      <td>0 1 1 1 1 1 ^ 0 1 0 1 1 0 = 0 1 1 1 1</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>0 1 1 0 0 0 ^ 0 1 1 1 0 1 = 0 1 1</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     context next_token\n",
       "6835       0 0 1 1 1 1 ^ 0 1 0 0 0 0 = 0 1 1  [0, 1, 0]\n",
       "27678            1 1 1 1 0 1 ^ 1 1 0 0 1 0 =  [0, 1, 0]\n",
       "18078    1 0 1 0 0 0 ^ 0 1 0 1 1 0 = 1 1 1 1  [0, 1, 0]\n",
       "14047  0 1 1 1 1 1 ^ 0 1 0 1 1 0 = 0 1 1 1 1  [0, 1, 0]\n",
       "10958      0 1 1 0 0 0 ^ 0 1 1 1 0 1 = 0 1 1  [0, 1, 0]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the `df` dataframe up into train, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "trainval, test = sklearn.model_selection.train_test_split(df)\n",
    "train, validation = sklearn.model_selection.train_test_split(trainval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `keras.layers.TextVectorization` object with the following constructor parameters:\n",
    "\n",
    "- split=\"whitespace\"\n",
    "- standardize=None\n",
    "- output_sequence_length=26 (the longest possible sequence)\n",
    "\n",
    "Adapt it to the training data (the `context` column) and vectorise the training, validation and test texts.\n",
    "\n",
    "(Bonus challenge: this is one of the few times where you can actually give the vectorizer a vocabulary, and\n",
    "you don't have to adapt from training data. Can you figure out how?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 15:53:27.096359: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "vectoriser = keras.layers.TextVectorization(\n",
    "    split=\"whitespace\", standardize=None, \n",
    "    output_sequence_length=21\n",
    ")\n",
    "vectoriser.adapt(train.context)\n",
    "\n",
    "train_data = vectoriser(train.context)\n",
    "validation_data = vectoriser(validation.context)\n",
    "test_data = vectoriser(test.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target values need to be converted into tensorflow Tensors. Unfortunately, `tf.convert_to_tensor` doesn't\n",
    "handle pandas Series correctly. Use this work-around:\n",
    "\n",
    "`train_y = tf.convert_to_tensor(list(train.next_token))`\n",
    "\n",
    "(Create `train_y`, `validation_y` and `test_y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tf.convert_to_tensor(list(train.next_token))\n",
    "validation_y = tf.convert_to_tensor(list(validation.next_token))\n",
    "test_y = tf.convert_to_tensor(list(test.next_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with:\n",
    "\n",
    "- an input layer\n",
    "\n",
    "- an embedding layer (a 4-dimensional embedding space will be sufficient)\n",
    "\n",
    "- a bidirectional LSTM layer with 16 neurons in it\n",
    "\n",
    "- an output layer of 3 dense neurons with a softmax activation\n",
    "\n",
    "Compile it, and use a loss function of `categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 21)]              0         \n",
      "                                                                 \n",
      " embedding_8 (Embedding)     (None, 21, 4)             16        \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 32)               2688      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,803\n",
      "Trainable params: 2,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(21,))\n",
    "embedding = keras.layers.Embedding(\n",
    "    input_dim=4, output_dim=4)(inputs)\n",
    "thinking_layer = keras.layers.Bidirectional(\n",
    "    keras.layers.LSTM(16))(embedding)\n",
    "output_layer = keras.layers.Dense(\n",
    "    3,\n",
    "    activation=\"softmax\")(thinking_layer)\n",
    "model = keras.Model(\n",
    "    inputs=inputs,\n",
    "    outputs=output_layer)\n",
    "model.summary()\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model using the training data, add validation data and early stopping. You'll find that it \n",
    "reaches 100% accuracy after about 100-120 epochs.\n",
    "\n",
    "Surprisingly, it doesn't ever overfit. Make a graph of it if you want to (or just watch the numbers\n",
    "fly past as it trains).\n",
    "\n",
    "While you are waiting for this to complete, it would be a great time to **do the student evaluation survey now**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 15:53:32.503717: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-14 15:53:32.698062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-14 15:53:32.708601: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-14 15:53:32.868202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-14 15:53:32.882677: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.7501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 15:53:45.549598: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-14 15:53:45.624862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-14 15:53:45.631813: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - 16s 29ms/step - loss: 0.5933 - accuracy: 0.7501 - val_loss: 0.4517 - val_accuracy: 0.7900\n",
      "Epoch 2/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.4515 - accuracy: 0.7889 - val_loss: 0.4462 - val_accuracy: 0.7919\n",
      "Epoch 3/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.4517 - accuracy: 0.7883 - val_loss: 0.4390 - val_accuracy: 0.7954\n",
      "Epoch 4/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.4431 - accuracy: 0.7941 - val_loss: 0.4519 - val_accuracy: 0.7963\n",
      "Epoch 5/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.4351 - val_accuracy: 0.7995\n",
      "Epoch 6/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.4314 - accuracy: 0.8024 - val_loss: 0.4410 - val_accuracy: 0.8049\n",
      "Epoch 7/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.4168 - accuracy: 0.8060 - val_loss: 0.4374 - val_accuracy: 0.7958\n",
      "Epoch 8/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.4069 - accuracy: 0.8088 - val_loss: 0.4020 - val_accuracy: 0.8099\n",
      "Epoch 9/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.3921 - accuracy: 0.8149 - val_loss: 0.3855 - val_accuracy: 0.8179\n",
      "Epoch 10/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.3697 - accuracy: 0.8221 - val_loss: 0.3529 - val_accuracy: 0.8344\n",
      "Epoch 11/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.3396 - accuracy: 0.8438 - val_loss: 0.3289 - val_accuracy: 0.8460\n",
      "Epoch 12/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.3321 - accuracy: 0.8528 - val_loss: 0.3183 - val_accuracy: 0.8508\n",
      "Epoch 13/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.3120 - accuracy: 0.8633 - val_loss: 0.3023 - val_accuracy: 0.8558\n",
      "Epoch 14/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2933 - accuracy: 0.8669 - val_loss: 0.2965 - val_accuracy: 0.8633\n",
      "Epoch 15/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2923 - accuracy: 0.8743 - val_loss: 0.2851 - val_accuracy: 0.8717\n",
      "Epoch 16/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2873 - accuracy: 0.8757 - val_loss: 0.2776 - val_accuracy: 0.8770\n",
      "Epoch 17/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.2814 - accuracy: 0.8766 - val_loss: 0.2714 - val_accuracy: 0.8815\n",
      "Epoch 18/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.2730 - accuracy: 0.8823 - val_loss: 0.2640 - val_accuracy: 0.8869\n",
      "Epoch 19/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2702 - accuracy: 0.8863 - val_loss: 0.2632 - val_accuracy: 0.8856\n",
      "Epoch 20/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.2572 - accuracy: 0.8898 - val_loss: 0.2611 - val_accuracy: 0.8910\n",
      "Epoch 21/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2539 - accuracy: 0.8941 - val_loss: 0.2949 - val_accuracy: 0.8731\n",
      "Epoch 22/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2529 - accuracy: 0.8954 - val_loss: 0.2409 - val_accuracy: 0.8969\n",
      "Epoch 23/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2410 - accuracy: 0.9003 - val_loss: 0.2474 - val_accuracy: 0.8919\n",
      "Epoch 24/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 0.2353 - accuracy: 0.9020 - val_loss: 0.2502 - val_accuracy: 0.8875\n",
      "Epoch 25/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 0.2328 - accuracy: 0.9035 - val_loss: 0.2326 - val_accuracy: 0.9036\n",
      "Epoch 26/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2247 - accuracy: 0.9066 - val_loss: 0.2261 - val_accuracy: 0.9051\n",
      "Epoch 27/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2205 - accuracy: 0.9062 - val_loss: 0.2367 - val_accuracy: 0.8914\n",
      "Epoch 28/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2131 - accuracy: 0.9092 - val_loss: 0.2203 - val_accuracy: 0.9040\n",
      "Epoch 29/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2094 - accuracy: 0.9120 - val_loss: 0.2118 - val_accuracy: 0.9079\n",
      "Epoch 30/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.2042 - accuracy: 0.9129 - val_loss: 0.2145 - val_accuracy: 0.9070\n",
      "Epoch 31/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.2010 - accuracy: 0.9153 - val_loss: 0.2250 - val_accuracy: 0.9036\n",
      "Epoch 32/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1974 - accuracy: 0.9159 - val_loss: 0.2080 - val_accuracy: 0.9113\n",
      "Epoch 33/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.1938 - accuracy: 0.9169 - val_loss: 0.2294 - val_accuracy: 0.8969\n",
      "Epoch 34/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.1911 - accuracy: 0.9169 - val_loss: 0.2041 - val_accuracy: 0.9096\n",
      "Epoch 35/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1872 - accuracy: 0.9203 - val_loss: 0.1978 - val_accuracy: 0.9139\n",
      "Epoch 36/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.1841 - accuracy: 0.9200 - val_loss: 0.1895 - val_accuracy: 0.9178\n",
      "Epoch 37/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.1823 - accuracy: 0.9227 - val_loss: 0.1858 - val_accuracy: 0.9165\n",
      "Epoch 38/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.1794 - accuracy: 0.9249 - val_loss: 0.1852 - val_accuracy: 0.9195\n",
      "Epoch 39/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.1752 - accuracy: 0.9249 - val_loss: 0.2272 - val_accuracy: 0.9059\n",
      "Epoch 40/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1724 - accuracy: 0.9258 - val_loss: 0.1846 - val_accuracy: 0.9213\n",
      "Epoch 41/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.1675 - accuracy: 0.9271 - val_loss: 0.1855 - val_accuracy: 0.9189\n",
      "Epoch 42/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1649 - accuracy: 0.9291 - val_loss: 0.1862 - val_accuracy: 0.9215\n",
      "Epoch 43/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.1620 - accuracy: 0.9306 - val_loss: 0.1823 - val_accuracy: 0.9204\n",
      "Epoch 44/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1574 - accuracy: 0.9335 - val_loss: 0.1733 - val_accuracy: 0.9217\n",
      "Epoch 45/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.1568 - accuracy: 0.9340 - val_loss: 0.1644 - val_accuracy: 0.9284\n",
      "Epoch 46/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.1516 - accuracy: 0.9342 - val_loss: 0.1691 - val_accuracy: 0.9239\n",
      "Epoch 47/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1496 - accuracy: 0.9363 - val_loss: 0.1756 - val_accuracy: 0.9256\n",
      "Epoch 48/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1477 - accuracy: 0.9372 - val_loss: 0.1632 - val_accuracy: 0.9301\n",
      "Epoch 49/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1415 - accuracy: 0.9392 - val_loss: 0.1759 - val_accuracy: 0.9215\n",
      "Epoch 50/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1391 - accuracy: 0.9420 - val_loss: 0.1558 - val_accuracy: 0.9306\n",
      "Epoch 51/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.1299 - accuracy: 0.9441 - val_loss: 0.1529 - val_accuracy: 0.9342\n",
      "Epoch 52/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1244 - accuracy: 0.9480 - val_loss: 0.1320 - val_accuracy: 0.9420\n",
      "Epoch 53/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1186 - accuracy: 0.9493 - val_loss: 0.1507 - val_accuracy: 0.9345\n",
      "Epoch 54/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1145 - accuracy: 0.9529 - val_loss: 0.1226 - val_accuracy: 0.9457\n",
      "Epoch 55/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1090 - accuracy: 0.9531 - val_loss: 0.1314 - val_accuracy: 0.9423\n",
      "Epoch 56/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.1046 - accuracy: 0.9554 - val_loss: 0.1423 - val_accuracy: 0.9364\n",
      "Epoch 57/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 0.0999 - accuracy: 0.9583 - val_loss: 0.1142 - val_accuracy: 0.9490\n",
      "Epoch 58/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0963 - accuracy: 0.9599 - val_loss: 0.1106 - val_accuracy: 0.9528\n",
      "Epoch 59/200\n",
      "504/504 [==============================] - 15s 31ms/step - loss: 0.0919 - accuracy: 0.9619 - val_loss: 0.1224 - val_accuracy: 0.9475\n",
      "Epoch 60/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0894 - accuracy: 0.9638 - val_loss: 0.1184 - val_accuracy: 0.9500\n",
      "Epoch 61/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0853 - accuracy: 0.9655 - val_loss: 0.1078 - val_accuracy: 0.9535\n",
      "Epoch 62/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0833 - accuracy: 0.9659 - val_loss: 0.0947 - val_accuracy: 0.9598\n",
      "Epoch 63/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0779 - accuracy: 0.9679 - val_loss: 0.0905 - val_accuracy: 0.9611\n",
      "Epoch 64/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0749 - accuracy: 0.9672 - val_loss: 0.0859 - val_accuracy: 0.9654\n",
      "Epoch 65/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0709 - accuracy: 0.9699 - val_loss: 0.0857 - val_accuracy: 0.9656\n",
      "Epoch 66/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0663 - accuracy: 0.9727 - val_loss: 0.0704 - val_accuracy: 0.9719\n",
      "Epoch 67/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0613 - accuracy: 0.9756 - val_loss: 0.0828 - val_accuracy: 0.9658\n",
      "Epoch 68/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0561 - accuracy: 0.9763 - val_loss: 0.0822 - val_accuracy: 0.9648\n",
      "Epoch 69/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0509 - accuracy: 0.9793 - val_loss: 0.0782 - val_accuracy: 0.9697\n",
      "Epoch 70/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.0505 - val_accuracy: 0.9803\n",
      "Epoch 71/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0401 - accuracy: 0.9849 - val_loss: 0.0485 - val_accuracy: 0.9805\n",
      "Epoch 72/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0351 - accuracy: 0.9876 - val_loss: 0.0323 - val_accuracy: 0.9881\n",
      "Epoch 73/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0305 - accuracy: 0.9889 - val_loss: 0.0299 - val_accuracy: 0.9888\n",
      "Epoch 74/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.0329 - val_accuracy: 0.9883\n",
      "Epoch 75/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 0.0269 - val_accuracy: 0.9900\n",
      "Epoch 76/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0164 - val_accuracy: 0.9940\n",
      "Epoch 77/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0131 - val_accuracy: 0.9957\n",
      "Epoch 78/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0125 - val_accuracy: 0.9963\n",
      "Epoch 79/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "Epoch 80/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "Epoch 81/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0040 - val_accuracy: 0.9989\n",
      "Epoch 82/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
      "Epoch 83/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 84/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 86/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 9.8695e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1778 - val_accuracy: 0.9513\n",
      "Epoch 88/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 5.6803e-04 - val_accuracy: 0.9998\n",
      "Epoch 89/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
      "Epoch 90/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 91/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 9.6533e-04 - val_accuracy: 0.9996\n",
      "Epoch 92/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 1.2396e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 3.3789e-04 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9991\n",
      "Epoch 94/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 6.3509e-04 - accuracy: 0.9999 - val_loss: 1.0416e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 6.8971e-04 - accuracy: 0.9996 - val_loss: 1.1800e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 6.2111e-04 - accuracy: 0.9998 - val_loss: 5.7122e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 7.1502e-04 - accuracy: 0.9998 - val_loss: 1.0312e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 7.5012e-04 - accuracy: 0.9998 - val_loss: 1.8670e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 5.6787e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9994\n",
      "Epoch 101/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 9.3541e-04 - accuracy: 0.9998 - val_loss: 1.0095e-04 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
      "Epoch 103/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 5.3989e-04 - accuracy: 0.9998 - val_loss: 7.9477e-06 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 5.3608e-04 - accuracy: 0.9999 - val_loss: 6.2489e-06 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 2.6661e-04 - accuracy: 0.9999 - val_loss: 1.5032e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 3.1028e-04 - accuracy: 0.9998 - val_loss: 1.0545e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
      "Epoch 108/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 6.4161e-06 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 4.1913e-04 - accuracy: 0.9999 - val_loss: 3.0065e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 7.8975e-04 - accuracy: 0.9998 - val_loss: 6.2162e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 8.9305e-04 - accuracy: 0.9997 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - 14s 28ms/step - loss: 5.1614e-04 - accuracy: 0.9999 - val_loss: 1.4389e-04 - val_accuracy: 0.9998\n",
      "Epoch 113/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 6.1805e-06 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 6.6695e-05 - accuracy: 1.0000 - val_loss: 3.2481e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 7.9285e-06 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 6.9430e-04 - accuracy: 0.9998 - val_loss: 1.0025e-06 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 7.7533e-04 - accuracy: 0.9997 - val_loss: 1.2049e-05 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 1.3363e-04 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 9.9798e-04 - accuracy: 0.9999 - val_loss: 7.6973e-04 - val_accuracy: 0.9998\n",
      "Epoch 120/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0976 - val_accuracy: 0.9799\n",
      "Epoch 121/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 5.3013e-07 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 2.0356e-04 - accuracy: 0.9999 - val_loss: 3.0990e-04 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 6.8249e-07 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 8.0843e-04 - accuracy: 0.9998 - val_loss: 3.1853e-04 - val_accuracy: 0.9998\n",
      "Epoch 125/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 5.5451e-06 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 126/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 3.8988e-04 - accuracy: 0.9999 - val_loss: 7.5563e-06 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 4.3104e-05 - accuracy: 1.0000 - val_loss: 3.3159e-04 - val_accuracy: 0.9998\n",
      "Epoch 128/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 6.5523e-04 - accuracy: 0.9998 - val_loss: 4.3714e-06 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.9735e-04 - accuracy: 0.9999 - val_loss: 1.6493e-05 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 8.1749e-06 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 3.9690e-04 - accuracy: 0.9999 - val_loss: 1.0834e-07 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 2.2231e-04 - accuracy: 0.9999 - val_loss: 1.3524e-07 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 134/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 5.0092e-04 - accuracy: 0.9999 - val_loss: 3.6286e-07 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "504/504 [==============================] - 16s 32ms/step - loss: 4.9253e-04 - accuracy: 0.9999 - val_loss: 2.3638e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 6.7964e-08 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 3.6238e-05 - accuracy: 1.0000 - val_loss: 5.3528e-08 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.2678e-06 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.3912e-04 - accuracy: 0.9999 - val_loss: 3.1239e-05 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 8.9789e-05 - accuracy: 0.9999 - val_loss: 4.7008e-08 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.8967e-07 - accuracy: 1.0000 - val_loss: 2.0755e-08 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.2336e-04 - accuracy: 0.9999 - val_loss: 6.9080e-06 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.9555e-06 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 4.2434e-04 - accuracy: 0.9999 - val_loss: 1.2351e-08 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 6.8394e-06 - accuracy: 1.0000 - val_loss: 3.9581e-08 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 1.1776e-06 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.9673e-04 - accuracy: 0.9998 - val_loss: 7.0956e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 6.1454e-08 - accuracy: 1.0000 - val_loss: 3.9357e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 4.5834e-08 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.1204e-06 - accuracy: 1.0000 - val_loss: 9.3576e-09 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 3.2114e-05 - accuracy: 1.0000 - val_loss: 2.8139e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.3333e-05 - accuracy: 1.0000 - val_loss: 1.2329e-08 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 3.9300e-08 - accuracy: 1.0000 - val_loss: 2.9935e-09 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.0370e-08 - accuracy: 1.0000 - val_loss: 4.8784e-09 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.1405e-08 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 156/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.9148e-04 - accuracy: 0.9999 - val_loss: 4.8005e-08 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 2.3331e-07 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 8.8401e-09 - accuracy: 1.0000 - val_loss: 1.1213e-07 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.5226e-09 - accuracy: 1.0000 - val_loss: 1.8537e-08 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 1.0126e-09 - accuracy: 1.0000 - val_loss: 8.6258e-09 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 2.1577e-04 - accuracy: 0.9999 - val_loss: 2.3150e-08 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.6002e-06 - accuracy: 1.0000 - val_loss: 1.3615e-08 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 6.4774e-04 - accuracy: 0.9999 - val_loss: 1.7498e-06 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.5631e-04 - accuracy: 0.9999 - val_loss: 0.0168 - val_accuracy: 0.9968\n",
      "Epoch 165/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.9774e-04 - accuracy: 0.9999 - val_loss: 3.6521e-08 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 8.0087e-07 - accuracy: 1.0000 - val_loss: 8.1158e-09 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 1.2418e-09 - accuracy: 1.0000 - val_loss: 6.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "504/504 [==============================] - 16s 31ms/step - loss: 1.0540e-04 - accuracy: 0.9999 - val_loss: 1.1223e-06 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 1.6958e-07 - accuracy: 1.0000 - val_loss: 1.1570e-06 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 3.4486e-04 - accuracy: 0.9999 - val_loss: 1.4857e-08 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 2.3283e-09 - accuracy: 1.0000 - val_loss: 1.0644e-09 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 1.8183e-09 - accuracy: 1.0000 - val_loss: 4.9227e-09 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 7.0219e-10 - accuracy: 1.0000 - val_loss: 2.5500e-09 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 3.2374e-09 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 4.4349e-10 - accuracy: 1.0000 - val_loss: 9.9785e-10 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 3.4740e-10 - accuracy: 1.0000 - val_loss: 9.7567e-10 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 5.8392e-10 - accuracy: 1.0000 - val_loss: 3.1709e-09 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.3653e-10 - accuracy: 1.0000 - val_loss: 1.3970e-09 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.4392e-10 - accuracy: 1.0000 - val_loss: 4.4570e-09 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 1.9218e-10 - accuracy: 1.0000 - val_loss: 1.5079e-09 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 2.5870e-10 - accuracy: 1.0000 - val_loss: 6.2088e-10 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.0696e-10 - accuracy: 1.0000 - val_loss: 8.8697e-10 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.1435e-09 - accuracy: 1.0000 - val_loss: 1.0865e-09 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 3.1783e-10 - accuracy: 1.0000 - val_loss: 1.1309e-09 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.2913e-10 - accuracy: 1.0000 - val_loss: 1.8848e-09 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 1.9957e-10 - accuracy: 1.0000 - val_loss: 3.0379e-09 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 1.2565e-10 - accuracy: 1.0000 - val_loss: 2.8383e-09 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 1.4044e-10 - accuracy: 1.0000 - val_loss: 1.9292e-09 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 2.7348e-10 - accuracy: 1.0000 - val_loss: 1.2551e-08 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 2.0696e-10 - accuracy: 1.0000 - val_loss: 7.3175e-10 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 1.7000e-10 - accuracy: 1.0000 - val_loss: 7.7610e-10 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 2.6609e-10 - accuracy: 1.0000 - val_loss: 3.0600e-09 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 9.6089e-11 - accuracy: 1.0000 - val_loss: 1.0865e-09 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 8.8697e-11 - accuracy: 1.0000 - val_loss: 9.5350e-10 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 9.6089e-11 - accuracy: 1.0000 - val_loss: 2.1066e-09 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "504/504 [==============================] - 14s 28ms/step - loss: 8.1306e-11 - accuracy: 1.0000 - val_loss: 1.5744e-09 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "504/504 [==============================] - 15s 29ms/step - loss: 8.8697e-11 - accuracy: 1.0000 - val_loss: 3.1044e-09 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 8.8697e-11 - accuracy: 1.0000 - val_loss: 7.5835e-09 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "504/504 [==============================] - 14s 29ms/step - loss: 2.0807e-04 - accuracy: 0.9999 - val_loss: 1.8560e-08 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "504/504 [==============================] - 15s 30ms/step - loss: 2.8531e-09 - accuracy: 1.0000 - val_loss: 9.3132e-10 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, monitor=\"val_accuracy\")\n",
    "]\n",
    "history = model.fit(x=train_data, y=train_y,\n",
    "          validation_data=(validation_data, validation_y),\n",
    "          epochs=200,\n",
    "                    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student evaluation survey\n",
    "\n",
    "Set this value to true when you have done your student evaluation survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_have_completed_my_student_evaluation_survey = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API key\n",
    "\n",
    "Set this value to true when you have signed up for your API key.\n",
    "\n",
    "Remember that the API key can only be viewed once, so save it somewhere safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_have_signed_up_for_openai = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the test accuracy. It should be very good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - 7s 14ms/step - loss: 5.1740e-10 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.174013439912528e-10, 1.0]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_data, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that takes a bitwise-or arithmetic problem, an optional list of already-returned tokens and returns the next token.\n",
    "\n",
    "e.g. \n",
    "`get_next_token('1 0 0 1 0 0 | 0 0 0 0 0 1', '1 0 0')` should return \"1\".\n",
    "\n",
    "You will need to:\n",
    "\n",
    "- concatentate the first and second arguments (with an equals sign (=) between them\n",
    "\n",
    "- vectorize that input string\n",
    "\n",
    "- use the model to predict the probabilities of the three options for the next token (0,1 or .)\n",
    "\n",
    "- find the option that has the highest probability\n",
    "\n",
    "- return that as a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_token(arithmetic_problem, part_decoded_already=\"\"):\n",
    "    text = arithmetic_problem + \" = \" + part_decoded_already\n",
    "    text_vector = vectoriser([text])\n",
    "    probabilities = model.predict(text_vector, verbose=0)[0]\n",
    "    index_of_best = np.argmax(probabilities)\n",
    "    if index_of_best == 2:\n",
    "        return '.'\n",
    "    else:\n",
    "        return str(index_of_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it out with a sample problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_token('1 0 0 1 0 0 | 0 0 0 0 0 1', '1 0 0 1 0 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a function `get_full_answer` that calls `get_next_token` repeatedly with more context each time\n",
    "until it gets a `.`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_answer(arithmetic_problem):\n",
    "    part_decoded_already = \"\"\n",
    "    while True:\n",
    "        n = get_next_token(arithmetic_problem, part_decoded_already)\n",
    "        if n.strip() == '.':\n",
    "            break\n",
    "        part_decoded_already += ' ' + n\n",
    "    return part_decoded_already\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it out with a sample problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 1 0 0 1 0 1'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_full_answer('1 0 0 1 0 0 | 0 0 0 0 0 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers (Optional)\n",
    "\n",
    "Depending on how fast your computer is, how long it takes to do the student survey and so on, you \n",
    "might or might not have a lot of time left over.\n",
    "\n",
    "If you have run through all the above very quickly, go through the\n",
    "https://www.tensorflow.org/text/tutorials/transformer\n",
    "\n",
    "The tutorial is slightly out-of-date (as almost everything involving transformers is!)\n",
    "because it re-implements components that already exist in the `keras_nlp` library, but it\n",
    "is otherwise excellent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
