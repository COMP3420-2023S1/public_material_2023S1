{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Classification - The Oxford-IIIT Pet Dataset\n",
    "\n",
    "**Submission deadline: Friday 21 April, 11:55pm**\n",
    "\n",
    "**Assessment weight: 15% of the total unit assessment.**\n",
    "\n",
    "**Versions**\n",
    "  - 2023-03-27 V1.0: Initial release\n",
    "\n",
    "*Unless a Special Consideration request has been submitted and approved, a 5% penalty (of the total possible mark of the task) will be applied for each day a written report or presentation assessment is not submitted, up until the 7th day (including weekends). After the 7th day, a grade of ‘0’ will be awarded even if the assessment is submitted. The submission time for all uploaded assessments is **11:55 pm**. A 1-hour grace period will be provided to students who experience a technical concern. For any late submission of time-sensitive tasks, such as scheduled tests/exams, performance assessments/presentations, and/or scheduled practical assessments/labs, please apply for [Special Consideration](https://students.mq.edu.au/study/assessment-exams/special-consideration).*\n",
    "\n",
    "In this assignment you will complete tasks for an end-to-end image classification application. We will train and test the data using the Oxford-III Pet Dataset:\n",
    "\n",
    "- https://www.robots.ox.ac.uk/~vgg/data/pets/\n",
    "\n",
    "This is a small dataset with 37 breeds of cats and dogs. Please download the image files and annotations from the above link, and unzip it on your work directory. This will create the following two directories:\n",
    "\n",
    "- `images` - Images saved as jpg files, one file per image.\n",
    "- `annotations` - Image annotations for image segmentation, object detection, and image classification. The annotations are explained in the file `annotations/README`. Please read the file so that you understand how to use these annotations. In this assignment, we will only use the annotations for image classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to GitHub Classroom\n",
    "\n",
    "Please follow these steps to connect:\n",
    "\n",
    "1. Follow this invitation link and accept the invitation: https://classroom.github.com/a/LuWneNQe\n",
    "2. The link may ask you to sign in to GitHub (if you haven't signed in earlier). If you don't have a GitHub account, you will need to register.\n",
    "3. Once you have logged in with GitHub, you may need to select your email address to associate your GitHub account with your email address (if you haven't done it in a previous COMP3420 activity). If you can't find your email address, please skip this step and contact diego.molla-aliod@mq.edu.au so that he can do the association manually.\n",
    "4. Wait a minute or two, and refresh the browser until it indicates that your assignment repository has been created. Your repository is private to you, and you have administration privileges. Only you and the lecture will have access to it. The repository will be listed under the list of repositories belonging to this offering of COMP3420: https://github.com/orgs/COMP3420-2023S1/repositories\n",
    "5. In contrast with assignment 1 and the practical sessions, your assignment repository will be empty and will not include starter code. you need to add this Jupyter notebook and commit the changes.\n",
    "\n",
    "Please use the github repository linked to this GitHub classroom. Make sure that you continuously push commits and you provide useful commit comments. **1 mark of the assessment of this assignment is related to good practice with the use of GitHub.**\n",
    "\n",
    "\n",
    "# 2. Data augmentation\n",
    "\n",
    "Use the CIFAR10 dataset that we used in the practical of week 4. Below is some of the data preparation code that we used back then:\n",
    "\n",
    "1. Download and unzip the CIFAR10 dataset **hosted by kaggle**. CIFAR10 is a very popular dataset with 60,000 32x32 colour images distributed evenly across 10 classes. The dataset is included in the TensorFlow library, but we will download and prepare it, for practice for assignment 2.\n",
    "    - [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "2. Run the following code. This code converts the downloaded data into image files that will be stored in two folders:\n",
    "    - `cifar_images_train`\n",
    "    - `cifar_images_test`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (4 marks) - Data preparation and exploration\n",
    "\n",
    "### 1.1 (1 mark)\n",
    "\n",
    "The `annotations` directory has the files `trainval.txt` and `test.txt`. Write Python code that counts the number of samples for each of the 37 categories in each of these files. In a markdown text cell, and answer these questions, providing a justification:\n",
    "\n",
    "1. Are the data balanced? Comment on whether there are any categories with an unusually large or small number of samples, relative to the other categories.\n",
    "2. Are there any significant differences in the distribution of categories in `trainval.txt` with respect to `test.txt`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 (1 mark)\n",
    "\n",
    "Display 10 random images from the \"trainval\" data and the \"test\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 (1 mark)\n",
    "\n",
    "Split the `annotations/test.txt` list of files into `validation.txt` and `newtest.txt` so that half of the items in each category falls into `validation.txt`, and the other half into `newtest.txt`. It is up to you how to do the splitting, but make sure that the distribution of categories in each is similar. Show the distribution of category counts on the resulting `validation.txt` and `newtest.txt` to demonstrate that the distribution of category counts is half/half.\n",
    "\n",
    "To facilitate the next tasks, make sure that the files `validation.txt` and `newtest.txt` contain the full path of the image files relative to the folder where this notebook is located, for example, the first lines of `validation.txt` might be like this:\n",
    "\n",
    "```\n",
    "images/Abyssinian_99.jpg 1 1 1\n",
    "images/Abyssinian_25.jpg 1 1 1\n",
    "images/Abyssinian_78.jpg 1 1 1\n",
    "images/Abyssinian_86.jpg 1 1 1\n",
    "```\n",
    "\n",
    "Also to facilitate the next tasks of this assignment, write Python code that rewrites the contents of `annotations/trainval.txt` into a new file `training.txt` that also contains the full relative path of the images.\n",
    "\n",
    "The following are sample files. Your files should look similar to these.\n",
    "- [`training.txt`](training.txt)\n",
    "- [`validation.txt`](validation.txt)\n",
    "- [`newtest.txt`](newtest.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 (1 mark)\n",
    "\n",
    "Use TensorFlow's `TextLineDataset` to generate datasets for training, validation, and test. The datasets need to produce images that are re-sized to dimensions 200x200, and the values of the pixels are normalised to the range [0, 1]. For this task and following tasks in this assignment, use the files we provide:\n",
    "\n",
    "- [`training.txt`](training.txt)\n",
    "- [`validation.txt`](validation.txt)\n",
    "- [`newtest.txt`](newtest.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (4 marks) - A simple classifier\n",
    "\n",
    "Implement a simple classifier that uses these layers. You need to decide a reasonable ordering of the layers, and reasonable values of the various parameters in each layer.\n",
    "\n",
    "- Dense layers.\n",
    "- Dropout.\n",
    "- Final classification.\n",
    "\n",
    "The task will be composed of the following subtasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (2 marks)\n",
    "\n",
    "Create a simple model that just contains the following two layers:\n",
    "\n",
    "- A `Flatten` layer.\n",
    "- The output layer with the correct size and activation function.\n",
    "\n",
    "Then, train the model with the training data. Use the validation data to determine when to stop training. Determine whether the system is overfitting and at what point in the training stage (if it is overfitting).\n",
    "\n",
    "Finally, test the trained model on the test data and report the accuracy results.\n",
    "\n",
    "Do not worry if you see error messages of the form \"corrupt JPEG data\". The reason for this is that some of the images are not in the JPEG format. Feel free to remove these images (a web search will help you find the images from this set that do not have the correct JPEG format), or just ignore the errors.\n",
    "\n",
    "Also, you will probably obtain a very low accuracy, don't worry about that. Later you will try to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 (1 mark)\n",
    "\n",
    "Try a more complex architecture that has an additional hidden layer with dropout. For this more complex architecture, try various values of parameters including the following: \n",
    "\n",
    "- Hidden layer size\n",
    "- Dropout rate\n",
    "- Learning rate\n",
    "\n",
    "For this, use `keras-tuner` and run it with a reasonable choice of possible parameters and report on the optimal parameters and final evaluation results.\n",
    "\n",
    "In a separate Markdown text cell, justify your choice of potential parameters.\n",
    "\n",
    "Use the best model obtained here to report the evaluation results on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 (1 mark)\n",
    "\n",
    "Conduct error analysis with the best model that you have obtained from the previous experiments. In particular, answer the following questions.\n",
    "1. What animal breed is easier to detect?\n",
    "2. What animal breed is more difficult to detect?\n",
    "3. Display examples of classification errors.\n",
    "4. Display examples of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (5 marks) - A more complex classifier\n",
    "\n",
    "Implement a more complex classifier that incorporates convolutions and max pooling. You need to decide an optimal combination of layers and choice of parameters. The task will be composed of the following subtasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 (2 marks)\n",
    "\n",
    "Implement a model that includes a sequence of two `Conv2D`, each one followed with `MaxPooling2D`. Use reasonable numbers for the hyperparameters (number of filters, kernel size, pool size, activation), based on what we have seen in the lectures.\n",
    "\n",
    "Train the model with the training data and use the validation data to determine when to stop training. Determine whether and when it is overfitting, and report on the evaluation results with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 (1 mark)\n",
    "\n",
    "Try to improve on the above results by using a more complex architecture of your choice. In your solution, you must design the architecture from scratch (do not use a pre-trained model). Comment on the results. Compare with the best model of task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 (1 mark)\n",
    "\n",
    "Use MobileNet, pre-trained on imagenet as discussed in the lectures. Add the correct classification layer, and train it with your data. During training, make sure that you freeze the pre-trained weights. Make sure that you use a reasonable schedule for the learning rate. Evaluate and compare with other systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 (1 mark)\n",
    "\n",
    "Add a data augmentation stage to the model implemented in 3.3 and compare results vs. 3.3. In a Markdown text cell, justify the choice of data augmentation layers and their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding (1 mark)\n",
    "\n",
    "This mark will be assigned to submissions that have clean and efficient code and good in-code documentation of all code presented in this assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub Classroom (1 mark)\n",
    "\n",
    "These marks will be given to submissions that:\n",
    "\n",
    "- Have continuously committed changes to the GitHub repository at GitHub Classroom.\n",
    "- The commit messages are useful and informative.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Your submission should consist of this Jupyter notebook with all your code and explanations inserted into the notebook as text cells. **The notebook should contain the output of the runs. All code should run. Code with syntax errors or code without output will not be assessed.**\n",
    "\n",
    "**Do not submit multiple files. If you feel you need to submit multiple files, please contact Diego.Molla-Aliod@mq.edu.au first.**\n",
    "\n",
    "Examine the text cells of this notebook so that you can have an idea of how to format text for good visual impact. You can also read this useful [guide to the MarkDown notation](https://daringfireball.net/projects/markdown/syntax), which explains the format of the text cells.\n",
    "\n",
    "Each task specifies a number of marks. The final mark of the assignment is the sum of all the marks of each individual task.\n",
    "\n",
    "By submitting this assignment you are acknowledging that this is your own work. Any submissions that break the code of academic honesty will be penalised as per [the academic integrity policy](https://policies.mq.edu.au/document/view.php?id=3).\n",
    "\n",
    "## A note on the use of AI code generators\n",
    "\n",
    "In this assignment, we view AI code generators such as copilot, CodeGPT, etc as tools that can help you write code quickly. You are allowed to use these tools. If you choose to use them, make the following explicit:\n",
    "- What part of your code is based on the output of such tools, \n",
    "- What tools you used,\n",
    "- What prompts you used to generate the code, and\n",
    "- What modifications you made on the generated code.\n",
    "\n",
    "This will help us assess your work fairly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
