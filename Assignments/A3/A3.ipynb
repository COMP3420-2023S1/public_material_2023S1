{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Classification of TV Shows\n",
    "\n",
    "**Submission deadline: Friday 26 May, 11:55pm**\n",
    "\n",
    "**Assessment weight: 25% of the total unit assessment.**\n",
    "\n",
    "*Unless a Special Consideration request has been submitted and approved, a 5% penalty (of the total possible mark of the task) will be applied for each day a written report or presentation assessment is not submitted, up until the 7th day (including weekends). After the 7th day, a grade of ‘0’ will be awarded even if the assessment is submitted. The submission time for all uploaded assessments is **11:55 pm**. A 1-hour grace period will be provided to students who experience a technical concern. For any late submission of time-sensitive tasks, such as scheduled tests/exams, performance assessments/presentations, and/or scheduled practical assessments/labs, please apply for [Special Consideration](https://students.mq.edu.au/study/assessment-exams/special-consideration).*\n",
    "\n",
    "In this assignment you will complete tasks for an end-to-end genre classification application. We will train and test the data using the TVmaze data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TVmaze is a free online television information database that provides users with detailed information about TV shows, their episodes, and their schedules. The website was launched in 2005 and has since grown to become one of the most comprehensive TV databases available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce opportunities for copying and cheating, you will given a mostly-unique genre to work with. Add it to the next cell. Email Abid (or ask him when you see him) for your preference; if too many people have chosen that genre, he might ask you to pick again.\n",
    "\n",
    "Possibilities are:\n",
    "\n",
    "- Drama\n",
    "\n",
    "- Comedy\n",
    "\n",
    "- Romance\n",
    "\n",
    "- Crime\n",
    "\n",
    "- Action\n",
    "\n",
    "- Adventure\n",
    "\n",
    "- Anime\n",
    "\n",
    "- Mystery\n",
    "\n",
    "- History\n",
    "\n",
    "- Children\n",
    "\n",
    "- Thriller\n",
    "\n",
    "- Fantasy\n",
    "\n",
    "- Science-Fiction\n",
    "\n",
    "- Family\n",
    "\n",
    "- Food\n",
    "\n",
    "- Music\n",
    "\n",
    "- Travel\n",
    "\n",
    "- Sports\n",
    "\n",
    "- Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_genre = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure everyone has unique data (even if you share a genre), several questions will ask you\n",
    "to initialize a random number generator with `random_state_key`. Pick some number that is likely\n",
    "to be unique to you (e.g. the digits from your student number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 12345 with the digits from your student number, or some other number that is likely to be unique.\n",
    "random_state_key = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find a SQLite database (called `tvmaze.sqlite`) on iLearn. This is the data you will work from. Copy it into the same directory where you have put this jupyter notebook.\n",
    "\n",
    "The following cell should create a connection for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect(\"tvmaze.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Data\n",
    "\n",
    "In a few places, you will be asked to run queries on the names of characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell creates a dataframe called `characters_df` using this query:\n",
    "\n",
    "`select tvmaze_id, tvmaze_character_id, name from tvmaze_casting join tvmaze_characters using (tvmaze_character_id);`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the SQL query\n",
    "sql_query = \"\"\"\n",
    "select tvmaze_id, tvmaze_character_id, name\n",
    "from tvmaze_casting join tvmaze_characters\n",
    "using (tvmaze_character_id);\n",
    "\"\"\"\n",
    "\n",
    "# Read the data into a pandas dataframe\n",
    "characters_df = pd.read_sql_query(sql_query, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you aren't familiar with pandas, and just want to use raw `numpy`, you can use the `characters` array\n",
    "created in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = characters_df.to_numpy()\n",
    "characters.shape, characters.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to make it a little easier, here are the character names extracted as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_names = list(characters[:,2])\n",
    "character_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to start with 200 shows so that your program runs faster, and then later on replace it with\n",
    "500, or 1000 if you need more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells create:\n",
    "\n",
    "- A dataframe called `show_df` (if you are familiar with pandas)\n",
    "\n",
    "- A numpy array called `shownames` (the names of the shows to work with)\n",
    "\n",
    "- A numpy array called `descriptions` (which has the show descriptions)\n",
    "\n",
    "- A numpy array called `in_genre` (whether this show is in your target genre or not)\n",
    "\n",
    "- A numpy array called `tvmaze_ids` (the ID numbers of the shows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_genre_sql_query = f\"\"\"\n",
    "select tvmaze_id, showname, description, 0.0 as in_genre from tvmaze\n",
    "where tvmaze_id not in (select tvmaze_id from tvmaze_genre where genre = '{assigned_genre}')\n",
    "      and description is not null\n",
    "      and length(description) > 10\"\"\"\n",
    "\n",
    "in_genre_sql_query = f\"\"\"select tvmaze_id, showname, description, 1.0 as in_genre from tvmaze\n",
    "where tvmaze_id in (select tvmaze_id from tvmaze_genre where genre = '{assigned_genre}')\n",
    "      and description is not null\n",
    "      and length(description) > 10\n",
    "\"\"\"\n",
    "\n",
    "out_of_genre_df = pd.read_sql(out_of_genre_sql_query, connection)\n",
    "in_genre_df = pd.read_sql(in_genre_sql_query, connection)\n",
    "show_df = pd.concat([out_of_genre_df.sample(data_size, random_state=random_state_key), \n",
    "                     in_genre_df.sample(data_size, random_state=random_state_key)])\n",
    "show_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ids = show_df.tvmaze_id.to_numpy()\n",
    "descriptions = show_df.description.to_numpy()\n",
    "in_genre = show_df.in_genre.to_numpy()\n",
    "shownames = show_df.showname.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (3 marks) - Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 (1 mark)\n",
    "\n",
    "We all know that James Bond gets his gadgets from Q. Are there other shows where a character has a \n",
    "one-letter name?\n",
    "\n",
    "Write a regular expression that matches a single upper-case letter, and use it to check against\n",
    "the characters in `character_names`.\n",
    "\n",
    "How many shows do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 (1 mark)\n",
    "\n",
    "Write a regular expression that finds medical doctors. A medical doctor might be \"Dr.\" or \"Doctor\" or \"Dr\".\n",
    "\n",
    "Watch out for:\n",
    "\n",
    "- JUDr. Augusta (who has a PhD in law)\n",
    "\n",
    "- MUDr. Sova (who is a doctor)\n",
    "\n",
    "- The Doctor (a science fiction character, who isn't a medical doctor)\n",
    "\n",
    "- The Sixth Doctor (the same science fiction character, there are fifteen of them)\n",
    "\n",
    "Assume that Dr. Death and Dr. Teeth are doctors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 (1 mark)\n",
    "\n",
    "Write a regular expression to find Cyrillic alphabet character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (5 marks) - lexico-semantic preparation for a classifier\n",
    "\n",
    "For this task only, consider the output of `nltk.word_tokenize()` to be \n",
    "what we mean by a \"word\". Be case insensitive (i.e. lowercase all\n",
    "texts before processing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 (2 marks)\n",
    "\n",
    "Calculate:\n",
    "\n",
    "- two measures of the corpus size: the total number of words used in all descriptions, and the total number of TV shows\n",
    "\n",
    "- the total number of distinct words in the descriptions (the vocabulary size)\n",
    "\n",
    "- the average number of words in each description (i.e. the average document length)\n",
    "\n",
    "- the average appearance count of each word (the hit ratio for search)\n",
    "\n",
    "- the coefficients of Herdan's Law\n",
    "\n",
    "Make a log-log plot to confirm that the data follows Herdan's Law. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 (1 mark)\n",
    "\n",
    "Calculate the current ratio of distinct vocabulary items to documents, and compare it\n",
    "to theoretical prediction from the formula:\n",
    "\n",
    "$$\n",
    "    \\frac{C}{V} = \\frac{ N^{1 - \\beta}}{k L}\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "- $C$ is the number of *documents* in the corpus.\n",
    "- $L$ is the average length of a document in the corpus\n",
    "- $V$ is the number of distinct vocabulary items\n",
    "- $N$ the number of words in the corpus\n",
    "- $k$ and $beta$ are the values you derived in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 (0.5 marks)\n",
    "\n",
    "Based on your answer to 2.2, you can reasonably expect that one of the\n",
    "best ways to improve our classifier will be to add more documents.\n",
    "\n",
    "If current trends continue, TVmaze will have information for a million\n",
    "shows in should happen in 2045.\n",
    "\n",
    "What would you expect for the following:\n",
    "\n",
    "- $C/V$\n",
    "\n",
    "- The total vocabulary size (using Herdan's Law)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 (0.5 marks)\n",
    "\n",
    "You will use this answer to tune the classifier in Task 4.\n",
    "\n",
    "We should exclude happax legomena from the vocabulary, since they cannot be useful to the classifier.\n",
    "\n",
    "How many words of vocabulary remain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 (1 mark)\n",
    "\n",
    "We have mentioned Chollet's heuristic in class:\n",
    "\n",
    "> It turns out that when approaching a new text-classification task, you should pay close attention to the ratio between the number of samples in your training data and the mean number of words per sample (see figure 11.11). If that ratio is small—less than 1,500—then the bag-of-bigrams model will perform better (and as a bonus, it will be much faster to train and to iterate on too). If that ratio is higher than 1,500, then you should go with a sequence model.\n",
    "\n",
    "Calculate this ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (5 marks) - Information retrieval\n",
    "\n",
    "In this task you are going to create a naive search engine that will let you find a \"similar\"\n",
    "TV show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a randomly-selected show for you to use in this section. You will also use the data\n",
    "in `show_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_show = show_df[show_df.in_genre == 1.0].sample(n=1, random_state=random_state_key)\n",
    "selected_show.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_show.iloc[0].description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 (2 marks)\n",
    "\n",
    "Vectorise the `description` of each show using TFIDF. \n",
    "\n",
    "- Vectorise words and bigrams\n",
    "\n",
    "- Only include words and bigrams that appear twice\n",
    "\n",
    "- Only include words and bigrams that appear in less than 50% of the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 (1 mark)\n",
    "\n",
    "Write code that shows the size of this new vocabulary (the total number of words and bigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 (2 marks)\n",
    "\n",
    "Iterate over the shows that don't have your genre to find the show whose description is most\n",
    "similar (using cosine similarity) to the show that was chosen for you.\n",
    "\n",
    "That is, you should end up with a show that:\n",
    "\n",
    "- Has a very similar description to the show described at the start of Task 3\n",
    "\n",
    "- Belongs to a diffferent genre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (10 marks) - detect genres\n",
    "\n",
    "In this task, we'll be building a naively simple model for identifying TV genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 (1 mark)\n",
    "\n",
    "Use an sklearn function to break your dataset into a training set, and a test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random number initializer to your \n",
    "`random_state_key` so that this notebook always returns the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 (1 mark)\n",
    "\n",
    "Create a vectorizer for your data, and prepare it on the descriptions in the training data. \n",
    "\n",
    "Set `max_tokens` to the value in your answer from 2.4 (plus 1 for the \"unknown\" token).\n",
    "\n",
    "(The vectorizer you used in section 3.1 was trained on all data, not just your training data,\n",
    "so cannot be re-used here without leaking test information into the training data.)\n",
    "\n",
    "It should use TFIDF weighting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 (1 mark)\n",
    "\n",
    "Use the vectorizer to transform the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 (2 marks)\n",
    "\n",
    "We are creating a logistic regression model using Keras, which we will use\n",
    "to predict the genre of a TV show based on its description.\n",
    "\n",
    "Create a model based on the following:\n",
    "\n",
    "- An input layer with a shape based on the size of the vocabulary from your vectorization.\n",
    "\n",
    "- An output layer that uses a sigmoid activation function.\n",
    "\n",
    "Compile your model (choose an appropriate loss, and add 'accuracy' as a metric) and display a summary of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 (1 mark)\n",
    "\n",
    "Fit the model to the training data. The target variable is `in_genre`.\n",
    "Hold out 10% of the data as validation data. Stop when the loss in the \n",
    "validation data stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 (1 mark)\n",
    "\n",
    "Plot the training and validation loss and accuracy and confirm whether your model has begun to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 (1 mark)\n",
    "\n",
    "Report the accuracy of your model on the test data. It should be quite close to the\n",
    "validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 (1 mark)\n",
    "\n",
    "Extract the weights from the logistic regression layer, and match them up with the words in the\n",
    "vocabulary.\n",
    "\n",
    "Identify any vocabulary that is strongly associated with being in-genre or with being out-of-genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 (1 mark)\n",
    "\n",
    "Create a description of a new show to pitch to someone at Macquarie's Film and Television School that is going to be strongly associated with your genre. If you are lacking inspiration, this is the kind of task that \n",
    "large language models do quite well.\n",
    "\n",
    "Confirm that your model does correctly predict the genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 (2 marks) - embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1 (2 marks)\n",
    "\n",
    "Create a new model with an embedding layer, compile it, fit it and evaluate its performance on the training data\n",
    "set.\n",
    "\n",
    "Don't worry if it doesn't improve the model performance --- based on \n",
    "your answers to 2.3 we would expect an embedding layer to make it much worse, and based on 2.5 we would\n",
    "expect a sequence-to-sequence model to perform poorly as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Your submission should consist of this Jupyter notebook with all your code and explanations inserted into the notebook as text cells. **The notebook should contain the output of the runs. All code should run. Code with syntax errors or code without output will not be assessed.**\n",
    "\n",
    "**Do not submit multiple files. If you feel you need to submit multiple files, please contact greg.baker@mq.edu.au first.**\n",
    "\n",
    "Examine the text cells of this notebook so that you can have an idea of how to format text for good visual impact. You can also read this useful [guide to the MarkDown notation](https://daringfireball.net/projects/markdown/syntax), which explains the format of the text cells.\n",
    "\n",
    "Each task specifies a number of marks. The final mark of the assignment is the sum of all the marks of each individual task.\n",
    "\n",
    "By submitting this assignment you are acknowledging that this is your own work. Any submissions that break the code of academic honesty will be penalised as per [the academic integrity policy](https://policies.mq.edu.au/document/view.php?id=3).\n",
    "\n",
    "## A note on the use of AI code generators\n",
    "\n",
    "We view AI code generators such as copilot, CodeGPT, etc as tools that can help you write code quickly. You are allowed to use these tools. If you choose to use them, make the following explicit:\n",
    "- What part of your code is based on the output of such tools, \n",
    "- What tools you used,\n",
    "- What prompts you used to generate the code, and\n",
    "- What modifications you made on the generated code.\n",
    "\n",
    "This will help us assess your work fairly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
